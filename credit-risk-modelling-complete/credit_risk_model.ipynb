{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7fa9b085",
   "metadata": {},
   "source": [
    "# Credit Risk Modelling\n",
    "**Author:** Mohsin Iqbal\n",
    "\n",
    "Predict default risk from tabular credit data.\n",
    "\n",
    "> Replace `DATA_PATH` with a real dataset path when ready. This notebook will run out of the box on the included synthetic sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d38b72dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = 'data/german_credit_sample.csv'  # replace with real dataset path when ready\n",
    "SAVE_DIR = 'assets'\n",
    "RESULTS_JSON = 'results.json'\n",
    "\n",
    "import os\n",
    "os.makedirs(SAVE_DIR, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "608e5e35",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd, numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import classification_report, roc_auc_score, average_precision_score, precision_recall_curve, roc_curve\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Load data\n",
    " df = pd.read_csv(DATA_PATH)\n",
    "print(df.head())\n",
    "print(df['default'].value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cf2cb9a",
   "metadata": {},
   "source": [
    "## Preprocessing\n",
    "- Separate features/target\n",
    "- Identify numeric/categorical columns\n",
    "- Build ColumnTransformer\n",
    "- Train/test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f420df1",
   "metadata": {},
   "outputs": [],
   "source": [
    "target = 'default'\n",
    "X = df.drop(columns=[target])\n",
    "y = df[target]\n",
    "\n",
    "num_cols = X.select_dtypes(include=['int64','float64']).columns.tolist()\n",
    "cat_cols = X.select_dtypes(include=['object']).columns.tolist()\n",
    "\n",
    "numeric_tf = Pipeline(steps=[('scaler', StandardScaler())])\n",
    "categorical_tf = Pipeline(steps=[('onehot', OneHotEncoder(handle_unknown='ignore'))])\n",
    "\n",
    "preprocess = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_tf, num_cols),\n",
    "        ('cat', categorical_tf, cat_cols)\n",
    "    ]\n",
    ")\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42, stratify=y)\n",
    "len(X_train), len(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4de8d1f0",
   "metadata": {},
   "source": [
    "## Baseline: Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ff8f2a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "logit = Pipeline([\n",
    "    ('prep', preprocess),\n",
    "    ('clf', LogisticRegression(max_iter=1000, class_weight='balanced', n_jobs=None))\n",
    "])\n",
    "logit.fit(X_train, y_train)\n",
    "proba_lr = logit.predict_proba(X_test)[:,1]\n",
    "preds_lr = (proba_lr >= 0.5).astype(int)\n",
    "auc_lr = roc_auc_score(y_test, proba_lr)\n",
    "pr_auc_lr = average_precision_score(y_test, proba_lr)\n",
    "print('Logistic Regression AUC:', round(auc_lr,3), 'PR-AUC:', round(pr_auc_lr,3))\n",
    "print(classification_report(y_test, preds_lr))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecf69644",
   "metadata": {},
   "source": [
    "## Random Forest (with class weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "523aeb41",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = Pipeline([\n",
    "    ('prep', preprocess),\n",
    "    ('clf', RandomForestClassifier(n_estimators=400, random_state=42, class_weight='balanced_subsample', n_jobs=-1))\n",
    "])\n",
    "rf.fit(X_train, y_train)\n",
    "proba_rf = rf.predict_proba(X_test)[:,1]\n",
    "preds_rf = (proba_rf >= 0.5).astype(int)\n",
    "auc_rf = roc_auc_score(y_test, proba_rf)\n",
    "pr_auc_rf = average_precision_score(y_test, proba_rf)\n",
    "print('RandomForest AUC:', round(auc_rf,3), 'PR-AUC:', round(pr_auc_rf,3))\n",
    "print(classification_report(y_test, preds_rf))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbb21caa",
   "metadata": {},
   "source": [
    "## Curves & Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c56466cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_roc_pr(y_true, proba, label_prefix):\n",
    "    fpr, tpr, _ = roc_curve(y_true, proba)\n",
    "    aps = average_precision_score(y_true, proba)\n",
    "    prec, rec, _ = precision_recall_curve(y_true, proba)\n",
    "    \n",
    "    plt.figure()\n",
    "    plt.plot(fpr, tpr)\n",
    "    plt.plot([0,1],[0,1],'--')\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title(f'{label_prefix} ROC Curve (AUC={roc_auc_score(y_true, proba):.3f})')\n",
    "    plt.savefig(os.path.join(SAVE_DIR, f'{label_prefix}_roc.png'), bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "    plt.figure()\n",
    "    plt.plot(rec, prec)\n",
    "    plt.xlabel('Recall')\n",
    "    plt.ylabel('Precision')\n",
    "    plt.title(f'{label_prefix} Precision-Recall (AP={aps:.3f})')\n",
    "    plt.savefig(os.path.join(SAVE_DIR, f'{label_prefix}_pr.png'), bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "plot_roc_pr(y_test, proba_lr, 'logit')\n",
    "plot_roc_pr(y_test, proba_rf, 'rf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "900c96ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.inspection import permutation_importance\n",
    "# Permutation importance on RF pipeline\n",
    "X_test_pre = rf.named_steps['prep'].transform(X_test)\n",
    "rf_est = rf.named_steps['clf']\n",
    "# Permutation importance requires a predict function; we'll wrap via full pipeline using a lambda\n",
    "result = permutation_importance(rf, X_test, y_test, n_repeats=5, random_state=42, n_jobs=-1)\n",
    "importances = result.importances_mean\n",
    "# Extract feature names from preprocess\n",
    "cat_feature_names = rf.named_steps['prep'].named_transformers_['cat'].named_steps['onehot'].get_feature_names_out(cat_cols)\n",
    "feature_names = np.r_[num_cols, cat_feature_names]\n",
    "imp_df = pd.DataFrame({'feature': feature_names, 'importance': importances}).sort_values('importance', ascending=False).head(20)\n",
    "imp_df.to_csv(os.path.join(SAVE_DIR, 'top20_importances.csv'), index=False)\n",
    "imp_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a3d780a",
   "metadata": {},
   "source": [
    "## Save Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78a11d55",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = {\n",
    "    'auc': {'logit': float(auc_lr), 'rf': float(auc_rf)},\n",
    "    'pr_auc': {'logit': float(pr_auc_lr), 'rf': float(pr_auc_rf)}\n",
    "}\n",
    "with open(RESULTS_JSON, 'w') as f:\n",
    "    json.dump(results, f, indent=2)\n",
    "print(results)"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
